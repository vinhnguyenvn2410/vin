{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will extract structure from variations in historical stock prices. We don't have any target values (i.e., we don't know anything about the structure in the data) which is why this is an *unsupervised* machine learning task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a *Python dict* which stores a mapping from ticker symbols to company names. This is useful for presentation purposes later on in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a list of stocks we want to investigate\n",
    "symbol_dict = {\n",
    "    'TOT': 'Total',\n",
    "    'XOM': 'Exxon',\n",
    "    'CVX': 'Chevron',\n",
    "    'COP': 'ConocoPhillips',\n",
    "    'VLO': 'Valero Energy',\n",
    "    'MSFT': 'Microsoft',\n",
    "    'IBM': 'IBM',\n",
    "    'TWX': 'Time Warner',\n",
    "    'CMCSA': 'Comcast',\n",
    "    'CVC': 'Cablevision',\n",
    "    'YHOO': 'Yahoo',\n",
    "    'HPQ': 'HP',\n",
    "    'AMZN': 'Amazon',\n",
    "    'TM': 'Toyota',\n",
    "    'CAJ': 'Canon',\n",
    "    'MTU': 'Mitsubishi',\n",
    "    'SNE': 'Sony',\n",
    "    'F': 'Ford',\n",
    "    'HMC': 'Honda',\n",
    "    'NAV': 'Navistar',\n",
    "    'NOC': 'Northrop Grumman',\n",
    "    'BA': 'Boeing',\n",
    "    'KO': 'Coca Cola',\n",
    "    'MMM': '3M',\n",
    "    'MCD': 'Mc Donalds',\n",
    "    'PEP': 'Pepsi',\n",
    "    'MDLZ': 'Kraft Foods',\n",
    "    'K': 'Kellogg',\n",
    "    'UN': 'Unilever',\n",
    "    'MAR': 'Marriott',\n",
    "    'PG': 'Procter Gamble',\n",
    "    'CL': 'Colgate-Palmolive',\n",
    "    'GE': 'General Electrics',\n",
    "    'WFC': 'Wells Fargo',\n",
    "    'JPM': 'JPMorgan Chase',\n",
    "    'AIG': 'AIG',\n",
    "    'AXP': 'American express',\n",
    "    'BAC': 'Bank of America',\n",
    "    'GS': 'Goldman Sachs',\n",
    "    'AAPL': 'Apple',\n",
    "    'SAP': 'SAP',\n",
    "    'CSCO': 'Cisco',\n",
    "    'TXN': 'Texas instruments',\n",
    "    'XRX': 'Xerox',\n",
    "    'LMT': 'Lookheed Martin',\n",
    "    'WMT': 'Wal-Mart',\n",
    "    'WBA': 'Walgreen',\n",
    "    'HD': 'Home Depot',\n",
    "    'GSK': 'GlaxoSmithKline',\n",
    "    'PFE': 'Pfizer',\n",
    "    'SNY': 'Sanofi-Aventis',\n",
    "    'NVS': 'Novartis',\n",
    "    'KMB': 'Kimberly-Clark',\n",
    "    'R': 'Ryder',\n",
    "    'GD': 'General Dynamics',\n",
    "    'RTN': 'Raytheon',\n",
    "    'CVS': 'CVS',\n",
    "    'CAT': 'Caterpillar',\n",
    "    'DD': 'DuPont de Nemours'}\n",
    "\n",
    "# Split dict into list of symbols and list of names\n",
    "symbols, names = np.array(list(symbol_dict.items())).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening and closing prices for the above symbols and the period 01-01-2009 to 01-01-2012 have been stored in *data/Open.csv* and *data/Close.csv* respectively. Inspect both files and note their structure.\n",
    "\n",
    "In the next cell, load the contents of each file using the *pd.read_csv(filepath, header=0, index_col=0)* and store them in *open_vals* and *close_vals* respectively.\n",
    "\n",
    "**Bonus Question:** Explain the two additional arguments *header=0* and *index_col=0* in the context of these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get opening prices\n",
    "\n",
    "\n",
    "# Get closing price\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Preprocess Data\n",
    "\n",
    "Before we cluster the dataset, we have to convert the data to the right format. In general, data preprocessing might involve *filling missing values*, *extraction of features*, and *standardization/normalization* of data.\n",
    "\n",
    "### Extract Features\n",
    "\n",
    "In this example, we will use daily percent change as the feature for our clustering algorithm. Please note that *there are many other possible feature combinations* that can be used.\n",
    "\n",
    "In the following cell, compute daily percent change (`(close_vals - open_vals) / open_vals`) and assign the result to a new variable `X`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate percent change\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus Exercise**: Experiment with other features (e.g., absolute difference) and see how it changes your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Cluster Data\n",
    "\n",
    "The data is in the right format now. *scikit-learn* provides convenient methods to cluster complex data. We will use the popular *k-means* clustering algorithm. *k-means* is a simple, yet powerful, clustering technique to partition a data set into k distinct, non-overlapping clusters/groups.\n",
    "\n",
    "Before we run *k-means*, we have to specify *how many clusters* the algorithm should generate.\n",
    "\n",
    "Create a variable `n_clusters` that holds the number of clusters we want to generate (e.g., start with 12 clusters). Afterwards, create a k-means clustering object with `KMeans(n_clusters)` and assign it to a variable called `kmeans`. To generate the clusters, call the `fit` command on the clustering object. The fit `command` requires one parameter which holds the data that we want to cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the number of clusters in a variable 'n_clusters'\n",
    "\n",
    "\n",
    "# Cluster the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Help: Clustering Data With Scikit-learn](http://scikit-learn.org/stable/modules/clustering.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus Exercise**: Experiment with the number of clusters and observe how it changes the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Display Results\n",
    "\n",
    "Let's combine the clustering results with the company names we specified in step 2 to visualize the clusters. Execute the code in the following cell and observe the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print results\n",
    "labels = kmeans.labels_\n",
    "for i in range(n_clusters):\n",
    "    print('Cluster %i: %s' % ((i + 1), ', '.join(names[labels == i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate Results\n",
    "\n",
    "### Elbow Method\n",
    "\n",
    "The *Elbow method* can help select the optimal number of clusters. It looks at the variance explained as a function of the number of clusters. We choose the number of clusters so that when adding another cluster, it does not give significantly better modeling of the data (i.e., the \"elbow\").\n",
    "\n",
    "Execute the following code to test the different clustering configurations and to visualize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_clusters = 1\n",
    "max_clusters = 20\n",
    "distortions = []\n",
    "for i in range(min_clusters, max_clusters+1):\n",
    "    km = KMeans(n_clusters=i,\n",
    "                init='k-means++',\n",
    "                n_init=10,\n",
    "                max_iter=300,\n",
    "                random_state=0)\n",
    "    km.fit(X)\n",
    "    distortions.append(km.inertia_)\n",
    "    \n",
    "# Plot\n",
    "plt.plot(range(min_clusters, max_clusters+1), distortions, marker='o')\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Distortion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the optimal number of clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Help: Determining the number of clusters in a data set](https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
